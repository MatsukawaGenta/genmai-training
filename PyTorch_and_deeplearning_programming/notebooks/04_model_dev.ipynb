{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU9dTlgPF-Km"
      },
      "source": [
        "# 4. 予測関数定義\n",
        "# 4. Prediction function definition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLjiUdMkF-Kv"
      },
      "outputs": [],
      "source": [
        "# 必要ライブラリのインポート\n",
        "# Import required library\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDn5PNK1F-Kw"
      },
      "outputs": [],
      "source": [
        "# PyTorch関連ライブラリ\n",
        "# Pytorch related libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchviz import make_dot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EvqxdjJF-Kw"
      },
      "outputs": [],
      "source": [
        "# デフォルトフォントサイズ変更\n",
        "# Change default font size\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# デフォルトグラフサイズ変更\n",
        "# Change default graph size\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# デフォルトで方眼表示ON\n",
        "# Turn grid display on\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "# numpyの浮動小数点の表示精度\n",
        "# floating point display precision of numpy\n",
        "np.set_printoptions(suppress=True, precision=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3WZJXXHF-Kw"
      },
      "source": [
        "## 4.4 擬似コードとしての予測関数\n",
        "## 4.4 Prediction function as pseudocode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMdb2lxdF-Kw"
      },
      "outputs": [],
      "source": [
        "# レイヤー関数定義\n",
        "# Layer function definition\n",
        "\n",
        "# 最初の線形関数\n",
        "# First linear function\n",
        "# Input numbers: 784\n",
        "# Output numbers: 128\n",
        "l1 = nn.Linear(784, 128)\n",
        "\n",
        "# 2番目の線形関数\n",
        "# Second linear function\n",
        "# Input numbers: 128\n",
        "# Output numbers: 10\n",
        "l2 = nn.Linear(128, 10)\n",
        "\n",
        "# 活性化関数\n",
        "# Activation function\n",
        "relu = nn.ReLU(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9HCp5nUF-Kx"
      },
      "outputs": [],
      "source": [
        "# 入力テンソルから出力テンソルを計算\n",
        "# Calculating output tensor from input tensor\n",
        "\n",
        "# ダミー入力データを作成\n",
        "# Creating dummy input data\n",
        "inputs = torch.randn(100, 784)\n",
        "\n",
        "# 中間テンソル1の計算\n",
        "# Calculation of intermediate tensor 1\n",
        "m1 = l1(inputs)\n",
        "\n",
        "# 中間テンソル2の計算\n",
        "# Calculation of intermediate tensor 2\n",
        "m2 = relu(m1)\n",
        "\n",
        "# 出力テンソルの計算\n",
        "# Calculation of output tensor\n",
        "outputs = l2(m2)\n",
        "\n",
        "# 入力テンソルと出力テンソルのshape確認\n",
        "# Chack shape of input and output tensor\n",
        "print('入力テンソル', inputs.shape)\n",
        "print('出力テンソル', outputs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1pBFECMF-Kx"
      },
      "outputs": [],
      "source": [
        "# nn.Sequentialを使って、全体を合成関数として定義\n",
        "# Define the whole as a composite function using nn.Sequential\n",
        "\n",
        "net2 = nn.Sequential(\n",
        "    l1,\n",
        "    relu,\n",
        "    l2\n",
        ")\n",
        "\n",
        "outputs2 = net2(inputs)\n",
        "\n",
        "# 入力テンソルと出力テンソルのshape確認\n",
        "# Check shape of input and output tensor\n",
        "print('入力テンソル', inputs.shape)\n",
        "print('出力テンソル', outputs2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQf1DBaS8FZm"
      },
      "source": [
        "## 4.7　活性化関数の目的\n",
        "## 4.7  The purpose of activation function\n",
        "\n",
        "当コラムでは予測結果のグラフ(図4-9から図4-11) が重要で、そのための実装コードの意味が現段階でわからなくて構いません。\n",
        "\n",
        "In this column, the graph of prediction result (from figure 4-9 to 4-11) is important, so it's OK you don't understand the meaning of code for now.\n",
        "\n",
        "以下のコードがあくまで参考情報としての提示になります\n",
        "\n",
        "The following code is provided for reference purpose only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7apEGDq8zS7"
      },
      "source": [
        "#### 学習用のデータの計算\n",
        "#### Calculation of learning data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRauI6Z7Gvz8"
      },
      "outputs": [],
      "source": [
        "# 訓練データ、検証データの計算\n",
        "# Calculation of training and validation data\n",
        "np.random.seed(123)\n",
        "x = np.random.randn(100,1)\n",
        "\n",
        "# yの値はx^2に乱数の要素を1/10程度付加した\n",
        "# The value of y has added a random number factor of about 1/10 to x^2\n",
        "y = x**2 + np.random.randn(100,1) * 0.1\n",
        "\n",
        "# データを50件ずつに分け、それぞれ訓練用、検証用とする\n",
        "# Divide the data into 50 sets, one for training and one for validation\n",
        "x_train = x[:50,:]\n",
        "x_test = x[50:,:]\n",
        "y_train = y[:50,:]\n",
        "y_test = y[50:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WubHpuSu9F2a"
      },
      "outputs": [],
      "source": [
        "# 散布図表示\n",
        "# Show scatter plot\n",
        "plt.scatter(x_train, y_train, c='b', label='訓練データ')\n",
        "plt.scatter(x_test, y_test, c='k', marker='x', label='検証データ')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCrl5qLz9yB8"
      },
      "outputs": [],
      "source": [
        "# 入力変数x と正解値 ytのTesor化\n",
        "# Convert input variable x and true value yt to tensor\n",
        "inputs = torch.tensor(x_train).float()\n",
        "labels = torch.tensor(y_train).float()\n",
        "\n",
        "inputs_test = torch.tensor(x_test).float()\n",
        "labels_test = torch.tensor(y_test).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3QIOgzv-OOO"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVl4DOk0-vhO"
      },
      "source": [
        "### 単回帰の場合\n",
        "###  Simple regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRyZGGMN9_d3"
      },
      "outputs": [],
      "source": [
        "# モデルの定義\n",
        "# Definition of the model\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        # 親クラスnn.Modulesの初期化呼び出し\n",
        "        # Call initialization of parent class nn.Modules\n",
        "        super().__init__()\n",
        "\n",
        "        # 出力層の定義\n",
        "        # Definition of output layer\n",
        "        self.l1 = nn.Linear(1, 1)   \n",
        "        \n",
        "    # 予測関数の定義\n",
        "    # Definition of prediction function\n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x) # 線形回帰 Linear regression\n",
        "        return x1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4P55Zk5-Cwk"
      },
      "outputs": [],
      "source": [
        "# 学習率\n",
        "# Learning rate\n",
        "lr = 0.01\n",
        "\n",
        "# インスタンス生成　(パラメータ値初期化)\n",
        "# Creating instance (Initializing parameter value)\n",
        "net = Net()\n",
        "\n",
        "# 最適化アルゴリズム: 勾配降下法\n",
        "# Optimization algorithm: gradient decent method\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 損失関数： 最小二乗誤差\n",
        "# Loss function: Least suqare error\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 繰り返し回数\n",
        "# Repeat count\n",
        "num_epochs = 10000\n",
        "\n",
        "# 評価結果記録用 (損失関数値のみ記録)\n",
        "# Validation results recording (recording only loss function values)\n",
        "history = np.zeros((0,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "po6RlG27-FqN"
      },
      "outputs": [],
      "source": [
        "# 繰り返し計算メインループ\n",
        "# Repeat calculation main loop\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    # 勾配値初期化\n",
        "    # Gradient value initialization\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 予測計算\n",
        "    # Prediction calculation\n",
        "    outputs = net(inputs)\n",
        "  \n",
        "    # 誤差計算\n",
        "    # error calculation\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # 勾配計算\n",
        "    # Gradient calculation\n",
        "    loss.backward()\n",
        "\n",
        "    # 勾配降下法の適用\n",
        "    # Applying gradient descent\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100回ごとに途中経過を記録する\n",
        "    # Recording the progress every 100 times\n",
        "    if ( epoch % 100 == 0):\n",
        "        history = np.vstack((history, np.array([epoch, loss.item()])))\n",
        "        print(f'Epoch {epoch} loss: {loss.item():.5f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-ClJcWw-XTk"
      },
      "outputs": [],
      "source": [
        "# 結果のグラフ化\n",
        "# Show the result graph\n",
        "labels_pred = net(inputs_test)\n",
        "\n",
        "plt.title('隠れ層なし　活性化関数なし')\n",
        "plt.scatter(inputs_test[:,0].data, labels_pred[:,0].data, c='b', label='予測値')\n",
        "plt.scatter(inputs_test[:,0].data, labels_test[:,0].data, c='k', marker='x',label='正解値')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAO6k3Nu-z85"
      },
      "source": [
        "### 疑似ディープラーニングの場合\n",
        "### Pseudo deep learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEQbY7qG-nBu"
      },
      "outputs": [],
      "source": [
        "# モデルの定義\n",
        "# Definition of model\n",
        "\n",
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        # 親クラスnn.Modulesの初期化呼び出し\n",
        "        # Call initializing parent class nn.modules\n",
        "        super().__init__()\n",
        "\n",
        "        # 出力層の定義\n",
        "        # Definition of output layer\n",
        "        self.l1 = nn.Linear(1, 10)\n",
        "        self.l2 = nn.Linear(10, 10)\n",
        "        self.l3 = nn.Linear(10,1)\n",
        "        \n",
        "    # 予測関数の定義\n",
        "    # Definition of prediction function\n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x)\n",
        "        x2 = self.l2(x1)\n",
        "        x3 = self.l3(x2)\n",
        "        return x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvbOfSCh-6mC"
      },
      "outputs": [],
      "source": [
        "# 学習率\n",
        "# Learning rate\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "# インスタンス生成　(パラメータ値初期化)\n",
        "# Creating instace (Initializing parameter value)\n",
        "net2 = Net2()\n",
        "\n",
        "# 最適化アルゴリズム: 勾配降下法\n",
        "# Optimizaiotn algorithm: gardient descent method\n",
        "optimizer = optim.SGD(net2.parameters(), lr=lr)\n",
        "\n",
        "# 損失関数： 最小二乗誤差\n",
        "# loss function: Least square error\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 繰り返し回数\n",
        "# Repeat count\n",
        "num_epochs = 10000\n",
        "\n",
        "# 評価結果記録用 (損失関数値のみ記録)\n",
        "# Validation result recording (Recording loss function value)\n",
        "history = np.zeros((0,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mUIKSmN-93V"
      },
      "outputs": [],
      "source": [
        "# 繰り返し計算メインループ\n",
        "# Repeat calculation main loop\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    # 勾配値初期化\n",
        "    # Initializing gradient value\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 予測計算\n",
        "    # Prediction calculation\n",
        "    outputs = net2(inputs)\n",
        "  \n",
        "    # 誤差計算\n",
        "    # error calculation\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # 勾配計算\n",
        "    # gradient calculation\n",
        "    loss.backward()\n",
        "\n",
        "    # 勾配降下法の適用\n",
        "    # Applying gradient descent method\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100回ごとに途中経過を記録する\n",
        "    # Recording the progress every 100 times\n",
        "    if ( epoch % 100 == 0):\n",
        "        history = np.vstack((history, np.array([epoch, loss.item()])))\n",
        "        print(f'Epoch {epoch} loss: {loss.item():.5f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Dem98PE_ApM"
      },
      "outputs": [],
      "source": [
        "# 結果のグラフ化\n",
        "# Show result graph\n",
        "labels_pred2 = net2(inputs_test)\n",
        "\n",
        "plt.title('隠れ層２層　活性化関数なし')\n",
        "plt.scatter(inputs_test[:,0].data, labels_pred2[:,0].data, c='b', label='予測値')\n",
        "plt.scatter(inputs_test[:,0].data, labels_test[:,0].data, c='k', marker='x',label='正解値')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFvMf5on_TwP"
      },
      "source": [
        "### ディープラーニング(活性化関数あり)の場合\n",
        "### Deep learning (with avtivation function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-oqefSk_FiB"
      },
      "outputs": [],
      "source": [
        "# モデルの定義\n",
        "# Definition of model\n",
        "\n",
        "class Net3(nn.Module):\n",
        "    def __init__(self):\n",
        "        # 親クラスnn.Modulesの初期化呼び出し\n",
        "        # Call initialization of parent class nn.Modules\n",
        "        super().__init__()\n",
        "\n",
        "        # 出力層の定義\n",
        "        # Definition of output layer\n",
        "        self.l1 = nn.Linear(1, 10)\n",
        "        self.l2 = nn.Linear(10, 10)\n",
        "        self.l3 = nn.Linear(10,1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "    # 予測関数の定義\n",
        "    # Definition of prediction function\n",
        "    def forward(self, x):\n",
        "        x1 = self.relu(self.l1(x))\n",
        "        x2 = self.relu(self.l2(x1))\n",
        "        x3 = self.l3(x2)\n",
        "        return x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W9FC-Hm_IDA"
      },
      "outputs": [],
      "source": [
        "# 学習率\n",
        "# Learning rate\n",
        "lr = 0.01\n",
        "\n",
        "# インスタンス生成　(パラメータ値初期化)\n",
        "# Creating instance (Initializing parameter value)\n",
        "net3 = Net3()\n",
        "\n",
        "# 最適化アルゴリズム: 勾配降下法\n",
        "# Optimization algorithm: gradient descent method\n",
        "optimizer = optim.SGD(net3.parameters(), lr=lr)\n",
        "\n",
        "# 損失関数： 最小二乗誤差\n",
        "# loss function: Least square error\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 繰り返し回数\n",
        "# repeat count\n",
        "num_epochs = 10000\n",
        "\n",
        "# 評価結果記録用 (損失関数値のみ記録)\n",
        "# Validation result recording (Recording only loss function value)\n",
        "history = np.zeros((0,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0EmBr7b_n9l"
      },
      "outputs": [],
      "source": [
        "# 繰り返し計算メインループ\n",
        "# Repeat calculation main loop\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    # 勾配値初期化\n",
        "    # Initializing gradient value\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 予測計算\n",
        "    # Prediction calculation\n",
        "    outputs = net3(inputs)\n",
        "  \n",
        "    # 誤差計算\n",
        "    # Error calculation\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # 勾配計算\n",
        "    # Gradient calculation\n",
        "    loss.backward()\n",
        "\n",
        "    # 勾配降下法の適用\n",
        "    # Applying gradient descent method\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100回ごとに途中経過を記録する\n",
        "    # Recording the progress every 100 times\n",
        "    if ( epoch % 100 == 0):\n",
        "        history = np.vstack((history, np.array([epoch, loss.item()])))\n",
        "        print(f'Epoch {epoch} loss: {loss.item():.5f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JFjZsuD_vBE"
      },
      "outputs": [],
      "source": [
        "# 結果の可視化\n",
        "# Visualizing resutls\n",
        "labels_pred3 = net3(inputs_test)\n",
        "\n",
        "plt.title('隠れ層２層　活性化関数あり')\n",
        "plt.scatter(inputs_test[:,0].data, labels_pred3[:,0].data, c='b', label='予測値')\n",
        "plt.scatter(inputs_test[:,0].data, labels_test[:,0].data, c='k', marker='x',label='正解値')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ch04_model_dev.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
