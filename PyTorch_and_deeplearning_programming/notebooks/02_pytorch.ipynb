{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2章 PyTorch入門\n",
    "# 2. Introduction of PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要ライブラリのインポート\n",
    "# Import required libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デフォルトフォントサイズ変更\n",
    "# Set default font size\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# デフォルトグラフサイズ変更\n",
    "# Set default graph size\n",
    "plt.rcParams['figure.figsize'] = (6,6)\n",
    "\n",
    "# デフォルトで方眼表示ON\n",
    "# Show grid\n",
    "plt.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 テンソル\n",
    "## 2.2 Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリインポート\n",
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorchライブラリ\n",
    "# Pytorch library\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### いろいろな階数のTensorを作る\n",
    "### Create tensors of various ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 0階テンソル (スカラー)\n",
    "# Rank 0 tensor (scalar)\n",
    "# dtypeからfloat32に変換するのを忘れないように。\n",
    "# もし忘れたらnumpyに自動で変換され、いくつかのライブラリが動かない\n",
    "# Don't be forget to convert from dtype to float32. \n",
    "# If you forgot this about NumPy variable, dtype will be converted to float64, and some Libraries doesn't work it. \n",
    "r0 = torch.tensor(1.0).float()\n",
    "\n",
    "# typeを調べる\n",
    "# Show type\n",
    "print(type(r0))\n",
    "\n",
    "# dtypeを調べる\n",
    "# Show dtype\n",
    "print(r0.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# shapeを調べる\n",
    "# Show shape\n",
    "print(r0.shape)\n",
    "\n",
    "# データを調べる\n",
    "# Show data\n",
    "print(r0.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "torch.float32\n",
      "torch.Size([5])\n",
      "tensor([1., 2., 3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "# 1階テンソル (ベクトル)\n",
    "# Rank 1 tensor (vector)\n",
    "\n",
    "# 1階のNumPy変数作成\n",
    "# Create rank 1 NumPy variable\n",
    "r1_np = np.array([1, 2, 3, 4, 5])\n",
    "print(r1_np.shape)\n",
    "\n",
    "# NumPyからテンソルに変換\n",
    "# Convert from NumPy to tensor\n",
    "r1 = torch.tensor(r1_np).float()\n",
    "\n",
    "# dtypeを調べる\n",
    "# Show dtype\n",
    "print(r1.dtype)\n",
    "\n",
    "# shapeを調べる\n",
    "# Show shape\n",
    "print(r1.shape)\n",
    "\n",
    "# データを調べる\n",
    "# Show data\n",
    "print(r1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "torch.Size([2, 3])\n",
      "tensor([[1., 5., 6.],\n",
      "        [4., 3., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# 2階テンソル (行列)\n",
    "# Rank 2 tensor (matrix)\n",
    "\n",
    "# 2階のNmPy変数作成\n",
    "# Create rank 2 Numpy variable\n",
    "r2_np = np.array([[1, 5, 6], [4, 3, 2]])\n",
    "print(r2_np.shape)\n",
    "\n",
    "# NumPyからテンソルに変換\n",
    "# Convert from NumPy to tensor\n",
    "r2 = torch.tensor(r2_np).float()\n",
    "\n",
    "# shapeを調べる\n",
    "# Show shape\n",
    "print(r2.shape)\n",
    "\n",
    "# データを調べる\n",
    "# Show data\n",
    "print(r2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2])\n",
      "tensor([[[-0.1115,  0.1204],\n",
      "         [-0.3696, -0.2404]],\n",
      "\n",
      "        [[-1.1969,  0.2093],\n",
      "         [-0.9724, -0.7550]],\n",
      "\n",
      "        [[ 0.3239, -0.1085],\n",
      "         [ 0.2103, -0.3908]]])\n"
     ]
    }
   ],
   "source": [
    "# ３階テンソル\n",
    "# Rank 3 tensor\n",
    "\n",
    "# 乱数seedの初期化\n",
    "# Initialize a random seed\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# shape=[3,2,2]の正規分布変数テンソルを作る\n",
    "# Create a normal distributed variable tensor with shape=[3, 2, 2]\n",
    "r3 = torch.randn((3, 2, 2))     # randn sets normal distributeed random numbers (average:0, variance:1) to elements\n",
    "\n",
    "# shapeを調べる\n",
    "# Show shape\n",
    "print(r3.shape)\n",
    "\n",
    "# データを調べる\n",
    "# Show data\n",
    "print(r3.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2, 2])\n",
      "tensor([[[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "# 4階テンソル\n",
    "# Rank 4 tensor\n",
    "\n",
    "# shape=[2,3,2,2]の要素がすべて1のテンソルを作る\n",
    "# Create tensor with shape=[2, 3, 2, 2] and all elements of it are 1\n",
    "r4 = torch.ones((2, 3, 2, 2))      # function ones sets 1.0 to all elements\n",
    "\n",
    "# shapeを調べる\n",
    "# Show shape\n",
    "print(r4.shape)\n",
    "\n",
    "# データを調べる\n",
    "# Show data\n",
    "print(r4.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整数型テンソルを作る\n",
    "### Create tensor of integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# r1 is a rank 1 tensor that has float32 data\n",
    "# This tensor is converted torch.int64 by long function \n",
    "r5 = r1.long()\n",
    "\n",
    "# dtypeを確認\n",
    "# Show dtype\n",
    "print(r5.dtype)\n",
    "\n",
    "# 値を確認\n",
    "# Show value\n",
    "print(r5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view関数\n",
    "### view function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "tensor([[-0.1115,  0.1204, -0.3696, -0.2404],\n",
      "        [-1.1969,  0.2093, -0.9724, -0.7550],\n",
      "        [ 0.3239, -0.1085,  0.2103, -0.3908]])\n"
     ]
    }
   ],
   "source": [
    "# 2階化\n",
    "# 要素数に-1を指定すると、この数を自動調整する\n",
    "# How to convert other rank like reshape of NumPy\n",
    "# Convert to rank 2 from rank 3 \n",
    "# Set -1 to only an element, then it will be automatically tuned.\n",
    "r6 = r3.view(3, -1)\n",
    "\n",
    "# shape確認\n",
    "# Show shape\n",
    "\n",
    "# In this case, the number of r3 elements is 12 ([3, 2, 2]:3*2*2=12)\n",
    "# And the number of r6 elements will be tuned to match 12, so r6.shape will be [3, 4]([3, x]:3*x=12)\n",
    "print(r6.shape)\n",
    "\n",
    "# 値確認\n",
    "# Show data\n",
    "print(r6.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n",
      "tensor([-0.1115,  0.1204, -0.3696, -0.2404, -1.1969,  0.2093, -0.9724, -0.7550,\n",
      "         0.3239, -0.1085,  0.2103, -0.3908])\n"
     ]
    }
   ],
   "source": [
    "# 1階化\n",
    "# 要素数に-1を指定すると、この数を自動調整する\n",
    "# How to convert other rank like reshape of NumPy\n",
    "# Convert to rank 1 from rank 3 \n",
    "# Set -1 to only an element, then it will be automatically tuned.\n",
    "r7 = r3.view(-1)\n",
    "\n",
    "# shape確認\n",
    "# Show shape\n",
    "# In this case, the number of r3 elements is 12 ([3, 2, 2]:3*2*2=12)\n",
    "# And the number of r6 elements will be tuned to match 12, so r7.shape will be [12]([12]:x=12)\n",
    "print(r7.shape)\n",
    "\n",
    "# 値確認\n",
    "# Show data\n",
    "print(r7.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other attriburtes\n",
    "### それ以外の属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad:  False\n",
      "device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# requires_grad属性\n",
    "# Requires_grad\n",
    "print('requires_grad: ', r1.requires_grad)\n",
    "\n",
    "# device属性\n",
    "# device\n",
    "print('device: ', r1.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item関数\n",
    "### item function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# スカラーテンソル(0階テンソル)に対してはitem関数で値を取り出せる\n",
    "# item function can get value of class with scaler tensor (rank 0)\n",
    "\n",
    "item = r0.item()\n",
    "\n",
    "print(type(item))\n",
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 5 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 0階以外のテンソルにitem関数は無効\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Be careful with item function. It can only use rank 0 tensor.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mr1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 5 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "# 0階以外のテンソルにitem関数は無効\n",
    "# Be careful with item function. It can only use rank 0 tensor.\n",
    "\n",
    "print(r1.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要素数が1つだけの1階テンソルはOK(2階以上でも同様)\n",
    "# When the number of elements is only one, it's OK to use rank more than 1 tensor.\n",
    "# example: shape is [1], or [1, 1]\n",
    "t1 = torch.ones(1)\n",
    "\n",
    "# shape確認\n",
    "# show shape\n",
    "print(t1.shape)\n",
    "\n",
    "# item関数呼び出し\n",
    "# call item function\n",
    "print(t1.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max関数\n",
    "### max function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元テンソルr2の確認\n",
    "# Show original tensor r2 (shape is [2, 3])\n",
    "print(r2)\n",
    "\n",
    "# max関数を引数なしで呼び出すと、全体の最大値が取得できる\n",
    "# Call max function without argument, and it will be able to get a maximum value from all elements\n",
    "print(r2.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.max関数\n",
    "# torch.max function\n",
    "\n",
    "# 2つめの引数はどの軸で集約するかを意味する\n",
    "# Second augument means which axis do you want to select\n",
    "\n",
    "# The case of rank 2 : axis=1 is row, axis=0 is column\n",
    "print(torch.max(r2, 1))\n",
    "print(torch.max(r2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 何番目の要素が最大値をとるかは、indicesを調べればいい\n",
    "# You can find out which order takes the maximum value by showing indices.\n",
    "# You can get only indices with putting [1] to \"print(torch.max(r2, 1))\"\n",
    "\n",
    "# 以下の計算は、多値分類で予測ラベルを求めるときによく利用されるパターン\n",
    "# The following calculation is a pattern that is often used when obtaining predicted labels in multi-level classification. \n",
    "print(torch.max(r2, 1)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy変数への変換\n",
    "### Convert to NumPy variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In following example, the tensor variable and the NumPy array are pointed same data, so use .copy() if you need.\n",
    "\n",
    "(More details are explained in 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy化\n",
    "# Convert to NumPy\n",
    "r2_np = r2.data.numpy()\n",
    "\n",
    "# type確認\n",
    "# Show type\n",
    "print(type(r2_np))\n",
    "\n",
    "# 値確認\n",
    "# Show value\n",
    "print(r2_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 ２次関数の勾配計算\n",
    "## 2.4 Gradient calculation of quadratic function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ準備\n",
    "### Preparating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xをnumpy配列で定義\n",
    "# Define x with NumPy array\n",
    "x_np = np.arange(-2, 2.1, 0.25)\n",
    "\n",
    "# xの値表示\n",
    "# Show the value of x\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 勾配計算用変数の定義\n",
    "### (1) The definition of variable for gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 勾配計算用変数の定義\n",
    "# (1) The definition of variable for gradient calculation\n",
    "\n",
    "x = torch.tensor(x_np, requires_grad=True, dtype=torch.float32)     # Set requires_grad = True\n",
    "\n",
    "# 結果確認\n",
    "# Show result\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About \"dtype=torch.float32\"\n",
    "\n",
    "Here we are specifying a dtype parameter instead of calling the float function.\n",
    "\n",
    "This is because when the float function is called, the copy function is called as a computation graph, and x is no longer a leaf node that can calculate the gradient value.\n",
    "\n",
    "In normal machine learning, the parameters are differentiated instead of x, so this is only supported this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) ２次関数の計算\n",
    "### (2) Calculate quadratic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) 2次関数の計算\n",
    "# (2) Calculate quadratic function\n",
    "\n",
    "# 裏で計算グラフが自動生成される\n",
    "# Computation graph is automatically generated\n",
    "y = 2 * x**2 +2\n",
    "\n",
    "# yの計算結果確認\n",
    "# Show the result of calculation of y\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフ描画\n",
    "# Show scatter plot\n",
    "\n",
    "plt.plot(x.data, y.data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配計算のため、sum 関数で 1階テンソルの関数値をスカラー化する\n",
    "# For gradient calculation, convert function value of rank 1 tensor to scalar with sum function\n",
    "\n",
    "# (sum 関数を各要素で偏微分した結果は1なので、元の関数の微分結果を取得可能 ) \n",
    "# (You can get the result of defferentiation of the original function, \n",
    "# because result of partial differentiation of the sum function with respect to each element is 1)\n",
    "\n",
    "# ( 詳細はサポートサイトの解説を参照のこと )\n",
    "# (For details, refer to the explanation on the support site)\n",
    "\n",
    "z = y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 計算グラフの可視化\n",
    "### (3) Visualization of computational graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) 計算グラフの可視化\n",
    "# (3) Visualization of computational graphs\n",
    "\n",
    "# 必要ライブラリのインポート\n",
    "# import required library\n",
    "from torchviz import make_dot\n",
    "\n",
    "# 可視化関数の呼び出し\n",
    "# Call the visualization function\n",
    "g = make_dot(z, params={'x': x})\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x: Leaf node. Variables for which gradient values ​​can be calculated. (17) is shape and it means rank 1 and 17 dimensions.\n",
    "\n",
    "AccumulateGrad: This is where to store gradient values.\n",
    " \n",
    "PowBackword0: Call exponential function (x**2)\n",
    "\n",
    "MulBackword0: Call multiplication function (2 * x**2)\n",
    "\n",
    "AddBackword0: Call add function (2 * x**2 + 2)\n",
    "\n",
    "SumBackword0: Call sum function (create scalar z from y)\n",
    "\n",
    "(): Output. () is shape and it means rank 0 and scalar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 勾配計算\n",
    "### (4) Gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) 勾配計算\n",
    "# (4) Gradient calculation\n",
    "\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 勾配値の取得\n",
    "### (5) Get the gradient value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) 勾配値の取得\n",
    "# (5) Get gradient values\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元の関数と勾配のグラフ化\n",
    "# Show graph of the original function and gradient\n",
    "\n",
    "plt.plot(x.data, y.data, c='b', label='y')\n",
    "plt.plot(x.data, x.grad.data, c='k', label='y.grad')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元の関数が2次関数なので、勾配計算の結果が直線になるのは、妥当な結果\n",
    "\n",
    "Since the original function is a quadratic function, it is reasonable that the result of the gradient calculation is a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) 勾配値の初期化\n",
    "### (6) Initialize gradient values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでもう一度勾配計算をしてみる。\n",
    "\n",
    "Here let's calculate gradient again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配の初期化せずに２度目の勾配計算\n",
    "# Second gradient computation without gradient initialization\n",
    "\n",
    "# x.gradがこれまでの結果を保持するので悪い例\n",
    "# This is bad example because x.grad keeps results so far\n",
    "\n",
    "y = 2 * x**2 + 2\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "\n",
    "# xの勾配確認\n",
    "# Show gradient of x\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "勾配値は、勾配計算の結果がどんどん加算されてしまう。そのため新しい値を計算したい場合、勾配値のリセットが必要。\n",
    "\n",
    "As for the gradient value, the result of the gradient calculation is added more and more. So if you want to calculate a new value, you need to reset the gradient value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) 勾配値の初期化は関数zero_()を使う\n",
    "# (6) Initialize gradient values with zero_() function\n",
    "\n",
    "x.grad.zero_()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 シグモイド関数の勾配計算\n",
    "## 2.5 Gradient calculation of sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シグモイド関数は数式で表すと次の形になるが今回はPyTorchで提供されている関数を利用する  \n",
    "\n",
    "The sigmoid function can be experssed in the following form, but this time, we will use the function provided by PyTorch.  \n",
    "$ y = \\dfrac{1}{1 + \\exp{(-x)}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シグモイド関数の定義\n",
    "# The definition of sigmoid function\n",
    "sigmoid = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) yの値の計算\n",
    "# (2) Calculate value of y\n",
    "y = sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフ描画\n",
    "# Show scatter plot\n",
    "plt.plot(x.data, y.data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最終結果をスカラーに加工する\n",
    "### Processing that scalarizes the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配計算のためには、最終値はスカラーの必要があるため、ダミーでsum関数をかける\n",
    "# For the gradient calculation, the final value must be a scalar, so a dummy sum function is applied\n",
    "z = y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 計算グラフの可視化\n",
    "### (3) Visualization of computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) 計算グラフの可視化\n",
    "# (3) Visualizaion of computational graph\n",
    "g = make_dot(z, params={'x': x})\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) 勾配計算\n",
    "# (4) gradient calculation\n",
    "z.backward()\n",
    "\n",
    "# (5) 勾配値の確認\n",
    "# (5) Show gradient value\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元の関数と勾配のグラフ化\n",
    "# Show original graph and gradient\n",
    "\n",
    "plt.plot(x.data, y.data, c='b', label='y')\n",
    "plt.plot(x.data, x.grad.data, c='k', label='y.grad')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シグモイド関数の勾配は、$y(1-y)$になる。  \n",
    "\n",
    "The gradient of sigmoid function is $y(1-y)$ .\n",
    "\n",
    "2次関数なので、$y=\\dfrac{1}{2}$の時(x=0の時)最大値$\\dfrac{1}{4}$を取る。  \n",
    "\n",
    "This is quadratic function, so when it is $y=\\dfrac{1}{2}$ (x=0), it takes muximum value $\\dfrac{1}{4}$.\n",
    "\n",
    "上のグラフは、この計算結果と一致している。  \n",
    "\n",
    "The graph above is consistent with this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) 勾配値の初期化は関数zero_()を使う\n",
    "# (6) Initialize gradient values with zero_() function\n",
    "\n",
    "x.grad.zero_()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (参考) シグモイド関数を独自に実装した場合\n",
    "### (Reference) An example of a manually implementation of the sigmoid function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シグモイド関数の定義\n",
    "# The definition of sigmoid function\n",
    "def sigmoid(x):\n",
    "    return(1/(1 + torch.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) yの値の計算\n",
    "# (2) Calculate the value of y\n",
    "y = sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフ描画\n",
    "# Show scatter graph\n",
    "plt.plot(x.data, y.data)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('The graph of sigmoid function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配計算のためには、最終値はスカラーの必要があるため、ダミーでsum関数をかける\n",
    "# For the gradient calculation, the final value must be a scalar, so a dummy sum function is applied\n",
    "z = y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) 計算グラフの可視化\n",
    "# (3) Visualization of computational graph\n",
    "params = {'x': x}\n",
    "g = make_dot(z, params=params)\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset x.grad\n",
    "x.grad.zero_()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) 勾配計算\n",
    "# (4) Gradient calculation\n",
    "z.backward()\n",
    "\n",
    "# (5) 勾配値の確認\n",
    "# (5) Show gradient value\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元の関数と勾配のグラフ化\n",
    "# Show original function and gradient\n",
    "plt.plot(x.data, y.data, c='b', label='y')\n",
    "plt.plot(x.data, x.grad.data, c='k', label='y.grad')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
